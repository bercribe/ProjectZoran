<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>Uncategorized &#8211; Project Zoran</title>
	<atom:link href="/category/uncategorized/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>A speed running research project</description>
	<lastBuildDate>Sat, 04 Sep 2021 03:44:40 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://s0.wp.com/i/webclip.png</url>
	<title>Uncategorized &#8211; Project Zoran</title>
	<link>/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">170658472</site>	<item>
		<title>The Expo</title>
		<link>/2019/04/19/the-expo/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Fri, 19 Apr 2019 18:59:32 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=83</guid>

					<description><![CDATA[I presented my work at the UMich design expo. It seemed to garner a lot of interest from passers by, especially from those attracted by the video game screenshots. General impressions seemed to be that it was a cool idea and that they&#8217;d like to see further development. Overall, it was a very positive experience<a class="more-link" href="/2019/04/19/the-expo/">Continue reading <span class="screen-reader-text">"The Expo"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I presented my work at the <a href="https://mdp.engin.umich.edu/design-expo/">UMich design expo</a>. It seemed to garner a lot of interest from passers by, especially from those attracted by the video game screenshots. General impressions seemed to be that it was a cool idea and that they&#8217;d like to see further development. Overall, it was a very positive experience for me, sharing a semester&#8217;s worth of work with interested parties.</p>



<p>Something interesting happened as I explained my process to the expo goers over and over again. I was able to refine my explanations based on the questions they were asking over time. Toward the end of the expo, I had my explanation down to a short and concise form that everyone seemed to be able to understand right away. I believe this refinement, in turn, helped improve my own understanding of the project. They say that you reach a new level of understanding in a topic when you can teach it to other people, and that seems to hold true.</p>



<p>I&#8217;d like to extend my thanks to anyone who took interest in my project. In particular, I&#8217;d like to thank the following: my independent research classmates for their interest and feedback in my project. <a href="http://www.mattmakesgames.com/">Matt Thorson</a> for making Celeste, without whom none of this would be possible. The <a href="https://discordapp.com/invite/AmZBJd8">Mt. Celeste Climbing Association</a> for making it easy for modders to get started with Celeste. <a href="https://github.com/sc2ad">sc2ad</a> for all his work on <a href="https://github.com/sc2ad/CelesteBot/tree/qlearning">CelesteBot</a>, which massively bootstrapped my whole project. And <a href="https://ayarger.com/">Austin Yarger</a>, for his continued enthusiasm and support for video games at UMich, as well as his breadth of knowledge and direction over the course of this project. The support of these individuals has made my research possible and enjoyable.</p>



<p>If anyone is reading this blog and would like to start contributing to <a href="https://github.com/sc2ad/CelesteBot/tree/qlearning">CelesteBot</a>, I encourage you to reach out to me or any other members of the Celeste community. My email is mwwaltz at umich dot edu, and my Discord tag is mawz#4488. Shoot me a message, I&#8217;d be happy to help.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">83</post-id>	</item>
		<item>
		<title>Winding down</title>
		<link>/2019/04/12/winding-down/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Fri, 12 Apr 2019 21:07:04 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=76</guid>

					<description><![CDATA[This week, I finished my research poster for the Umich Design Expo. I think it looks much more professional and gets to its point more concisely. I also decided the CelesteBot README was in need of improvement. I updated it with some &#8220;getting started&#8221; information that would be helpful for new users. Other than that,<a class="more-link" href="/2019/04/12/winding-down/">Continue reading <span class="screen-reader-text">"Winding down"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week, I finished my research poster for the <a href="https://mdp.engin.umich.edu/design-expo/">Umich Design Expo</a>. I think it looks much more professional and gets to its point more concisely.</p>



<figure class="wp-block-image"><img data-attachment-id="79" data-permalink="/2019/04/12/winding-down/project-zoran-5/" data-orig-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/46528-project-zoran-2.jpg?fit=2000%2C1500&amp;ssl=1" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Project Zoran" data-image-description="" data-image-caption="" data-medium-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/46528-project-zoran-2.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/46528-project-zoran-2.jpg?fit=750%2C563&amp;ssl=1" loading="lazy" width="750" height="563" src="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/46528-project-zoran-2.jpg?resize=750%2C563&#038;ssl=1" alt="" class="wp-image-79" data-recalc-dims="1" /></figure>



<div class="wp-block-file"><a href="/wp-content/uploads/2019/12/2b307-project-zoran-2.pdf">Project Zoran</a><a href="http://www.projectzoran.com/wp-content/uploads/2019/04/Project-Zoran-2.pdf" class="wp-block-file__button" download>Download</a></div>



<p>I also decided the <a href="https://github.com/sc2ad/CelesteBot/tree/qlearning">CelesteBot</a> README was in need of improvement. I updated it with some &#8220;getting started&#8221; information that would be helpful for new users.</p>



<p>Other than that, I just ran CelesteBot on Celeste level 1A for about 3,000 generations. I haven&#8217;t been able to find any settings that I think are holding it back, I believe the machine just needs to get lucky with the right mutation at this point. The only way for it to get lucky is by running the same data set for a long time, so that&#8217;s what I did. It hasn&#8217;t had a significant breakthrough yet, but you never know when it will figure out how to evolve.</p>



<p>That&#8217;s pretty much it, I&#8217;ve just been wrapping up and making it as easy as possible for a potential successor to pick up my work.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">76</post-id>	</item>
		<item>
		<title>Presentation Prep</title>
		<link>/2019/04/07/presentation-prep/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Sun, 07 Apr 2019 15:38:39 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=68</guid>

					<description><![CDATA[This week, I wanted to get fast mode working again and set up some differentiation in game entities for CelesteBot&#8217;s vision. Getting fast mode working again required some optimizations. I was able to identify the resource hog fairly quickly, it was the entity caching function that was run every frame. The function was wiping the<a class="more-link" href="/2019/04/07/presentation-prep/">Continue reading <span class="screen-reader-text">"Presentation Prep"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week, I wanted to get fast mode working again and set up some differentiation in game entities for CelesteBot&#8217;s vision.</p>



<p>Getting fast mode working again required some optimizations. I was able to identify the resource hog fairly quickly, it was the entity caching function that was run every frame. The function was wiping the cache manually and building it again every frame, which was slowing everything down. I changed it slightly so that instead of clearing the cache, it simply allocated new memory and used that, discarding the old memory. This helped significantly, but fast mode was still choppy at high speeds.</p>



<p>I decided it was time for some user facing settings. sc2ad had requested some settings for specifying the cache size, so I implemented those first. In addition, created a setting for specifying how fast the fast mode should be, as an integer multiplier of real time speed. Realizing that entities in Celeste don&#8217;t move fast enough to necessitate updates every frame, I also included a setting specifying how many frames to wait before updating the entity cache. The default is 10 frames, which is equivalent to 0.167 seconds. This change seems to work fine, and makes fast mode work great at 10x speed once more.</p>



<p>Lastly, I expanded the number of unique entities the bot would recognize through its vision to about 16. Everything present in 1A was covered, and I made it almost trivial to add new entities in the future. When the bot encounters entities that are uncategorized, it prints a message to the console specifying which entity to add and which enumerator to add it to. This should help when someone wants to run the bot on 2A in the future, for example. I made another pull request with my changes, the pull request is available <a href="https://github.com/sc2ad/CelesteBot/pull/2">here</a>.</p>



<p>Again, I ran the bot for a while with my changes in place. It got to generation 1,200 in the span of 20 hours, which is equivalent to 36,000 attempts. The population data file for generation 1,200 was 894 MB. It still didn&#8217;t make it past room 3, but it progressed a lot faster than before.</p>



<p>The rest of my work this week relates to the <a href="https://mdp.engin.umich.edu/design-expo/">UMich Design Expo</a>, at which I will present my findings with CelesteBot. I will have a poster with some of my key findings, and a computer running CelesteBot training live. I put together a draft of my poster, it is visible below.</p>



<figure class="wp-block-image"><img data-attachment-id="70" data-permalink="/2019/04/07/presentation-prep/project-zoran-2/" data-orig-file="https://i0.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/c4d78-project-zoran.jpg?fit=2000%2C1500&amp;ssl=1" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Project Zoran" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/c4d78-project-zoran.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/c4d78-project-zoran.jpg?fit=750%2C563&amp;ssl=1" loading="lazy" width="750" height="563" src="https://i0.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/c4d78-project-zoran.jpg?resize=750%2C563&#038;ssl=1" alt="" class="wp-image-70" data-recalc-dims="1" /></figure>



<div class="wp-block-file"><a href="/wp-content/uploads/2019/12/9577f-project-zoran.pdf">Project Zoran</a><a href="http://www.projectzoran.com/wp-content/uploads/2019/04/Project-Zoran.pdf" class="wp-block-file__button" download>Download</a></div>



<p>Short post this week, but that&#8217;s about all that happened. Next week I&#8217;ll be finalizing my poster and making any last minute changes needed for CelesteBot.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">68</post-id>	</item>
		<item>
		<title>Death Timers and Entity Caching v2</title>
		<link>/2019/03/31/death-timers-and-entity-caching-v2/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Sun, 31 Mar 2019 20:46:07 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=66</guid>

					<description><![CDATA[This week I was mainly trying to finalize my changes, fix any remaining critical bugs, and get some machine learning done. I noticed that the player was occasionally still resetting incorrectly. I went through a few different possible solutions, and settled one that appears to be as reliable as possible. When the player dies, the<a class="more-link" href="/2019/03/31/death-timers-and-entity-caching-v2/">Continue reading <span class="screen-reader-text">"Death Timers and Entity Caching v2"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week I was mainly trying to finalize my changes, fix any remaining critical bugs, and get some machine learning done.</p>



<p>I noticed that the player was occasionally still resetting incorrectly. I went through a few different possible solutions, and settled one that appears to be as reliable as possible. When the player dies, the death timer starts. As soon as the timer reaches 0, the player tries to reset the level. If the player doesn&#8217;t have control of the character, as is the case when the player is dead or the game is already resetting, the game fails to reset silently. I changed the code so the player would remain motionless after dying, and couldn&#8217;t suicide on spikes immediately, which took care of most instances of bad resets. The other bad resets were caused by a strange interaction between the other resetting mechanism. When the player hasn&#8217;t made significant progress for 4 or more seconds, the mod resets the level. However, if the player dies within this span of time, it can cause the game to be reset more than once, or not at all. To fix this, I gave the death timer priority over the stuck timer. If the player has died and the death timer is running, the stuck timer will not reset the player. I have seen no instances of bad resets since these changes were made.</p>



<p>Another problem I came across was present in the bot vision grid. I hadn&#8217;t noticed it before, but entities sometimes weren&#8217;t showing up in the grid at all due to the way the caching was done and the way Celeste loads entities. Most entities, including spikes, springs, and moving blocks, are not loaded into the game engine until the player is in the same room. However, the grid was checking for collisions in the next room before the player had entered in some cases and caching it in a grid that never updated, causing the bot to be blind to these entities forever. To fix this, I revamped my caching system slightly. It still caches tile locations permanently, but it caches entity locations once every frame. After that, I came across a silly off by one grid error caused by a difference in real coordinate to tile coordinate translations translations when working with positive and negative numbers. To fix this, I inserted a Math.Floor before casting the coordinate to an int. After these changes, the grid looked great and updated flawlessly for moving entities.</p>



<p>My final modification this week related to checkpoints. Previously, I had thought that the machine learning I was doing was using checkpoints in each room. In reality, it was failing to load any checkpoints and was throwing an exception to the log, instead defaulting to a single checkpoint at the location (10000, 10000). The reason for this was that there was no checkpoint present in the first room, and the code relies on the first checkpoint being in the first room to construct the checkpoint data structure. It was an easy fix, I simply added a new checkpoint to the checkpoint file.</p>



<p>Unfortunately, some of these changes have been processor intensive, and the fast mode that was developed last week has suffered for it. I decreased the speedup from 10x to 4x, but the frame rate still takes a big hit. Strangely, even when fast mode is disabled again, the frame rate stays choppy. I think there is probably a way to get fast mode working better, but it might require a closer look at the rest of the code base and significant optimizations. In the meantime, I think the trade off of speed for data accuracy is worth while. </p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio wp-embed-aspect-16-9"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" class="youtube-player" width="750" height="422" src="https://www.youtube.com/embed/dwt76_dVaOw?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>I ran CelesteBot some more, it&#8217;s still having trouble making it past the second room. I plan to keep running the bot in the background for the foreseeable future, only time will tell if it can make significant advancements past the first 2 rooms.</p>



<p>I also submitted a pull request for all my changes, if you&#8217;d like to see the code I&#8217;ve been working on all this time it&#8217;s available <a href="https://github.com/sc2ad/CelesteBot/pull/1">here</a>. For next week, I&#8217;ll likely continue running the bot, hunting bugs, optimizing code, and making trivial changes that won&#8217;t mess up my existing population data.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">66</post-id>	</item>
		<item>
		<title>Speeeed (and Serialization)</title>
		<link>/2019/03/22/speeeed-and-serialization/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Fri, 22 Mar 2019 19:16:55 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=62</guid>

					<description><![CDATA[This week my objectives were to speed up the machine learning process, and to develop a method for saving and loading CelesteBot brain data between sessions. I was able to accomplish both goals. Speeding up the game ended up being trivially easy. All that was necessary was to call the call the original Engine Update<a class="more-link" href="/2019/03/22/speeeed-and-serialization/">Continue reading <span class="screen-reader-text">"Speeeed (and Serialization)"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week my objectives were to speed up the machine learning process, and to develop a method for saving and loading CelesteBot brain data between sessions. I was able to accomplish both goals.</p>



<p>Speeding up the game ended up being trivially easy. All that was necessary was to call the call the original Engine Update function multiple times from within the hooked Engine Update function. I decided to call Update 10 times a function call, resulting in a 10x speedup in the game. I also added a keybinding to control the speedup &#8211; F engages fast mode and Shift+F disengages it.</p>



<p>The second task was harder to complete. The original developer sc2ad already had some logic in place to serialize and deserialize the Population (the data structure containing all NEAT specific data). It used the C# BinaryFormatter, and saved a copy of the population to a file every 3 generations by default. It also allowed the user to load a previous generation with the &#8216; key. Unfortunately, this logic was incomplete and produced files that were identical every time. These files could not be loaded and were effectively useless.</p>



<p>My first step was to fix the original logic by adding the [Serializable] tag to the Population class and all it&#8217;s necessary sub classes. This change alone resulted in checkpoint files that differed from each other. It was not enough to be able to load generations between sessions, though. The BinaryFormatter produces serialized classes that are meant to be used in the same program, it doesn&#8217;t save enough data to reconstruct a class across different sessions or programs. To do something like that, we need to serialize to an XML or JSON.</p>



<p>The next option I tried was the XmlSerializer. This fully serializes a class to an XML file, and can deserialize from that file in another program. Unfortunately, it is rather limited by its implementation method, as I discovered while trying to use it. It uses reflection to deserialize data, meaning it needs a parameterless constructor which it calls, followed by assigning public variables to their values. This by itself is OK, I was able to get around this requirement by creating empty parameterless constructors wherever required. I was also able to ignore variables for which creating a parameterless constructor was impossible, like the Celeste Player. The main deal breaker was it&#8217;s inability to serialize dictionaries. That, and it&#8217;s inability to handle circular references.</p>



<p>I moved on to DataContractJsonSerializer. This class functions a little differently from XmlSerializer. Instead of the [Serializable] tag, it uses [DataContract] for classes. Any variables you want serialized also have to be tagged with the [DataMember] tag. For nested classes, it&#8217;s usually necessary to specify known classes to be serialized and deserialized. My KnownTypes include CelestePlayer, ConnectionHistory, GeneConnection, Genome, Node, Population, and Species. After that, it&#8217;s a simple matter of using the serializer to save and load data to and from a file. I initially got errors because JsonSerializer is also unable to handle circular references. To fix this, I simply switched to the DataContractSerializer, and added (IsReference = true) to my [DataContract] tags. Suddenly, saving and loading populations worked perfectly!</p>



<p>These files also happen to be rather large. Checkpoint 0 was 13 MB, but by Checkpoint 300, the file size had grown to 34 MB. My folder containing checkpoints every 3 generations up to generation 675 is 6.83 GB. I will likely decrease the frequency of check pointing for future tests.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" class="youtube-player" width="750" height="422" src="https://www.youtube.com/embed/ygrkibDWOro?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>I ran CelesteBot for an extended duration again. Again, I ran into the issue mentioned last week, this time 11 minutes in. As a reminder, the mod didn&#8217;t reset the player to the beginning of the level correctly, so one species had an artificially high fitness. This currently appears to be the biggest barrier to the bot performing well. I will need to investigate methods of resetting the player without relying on a death timer, as the death timer has proven to be unreliable. This is my main goal for next week, along with fixing any minor bugs I come across. After that, I&#8217;d like to run the bot for an extended duration and see if it can beat level 1A. This is getting exciting, I&#8217;m so close to achieving something significant!</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">62</post-id>	</item>
		<item>
		<title>Expanding our Vision</title>
		<link>/2019/03/17/expanding-our-vision/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Sun, 17 Mar 2019 17:01:26 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=54</guid>

					<description><![CDATA[This week I wanted to focus on improving the vision for CelesteBot. As noted in the last post, 10&#215;10 vision worked fine but anything much bigger tanked the game&#8217;s frame rate. I looked at what the mod was doing behind the scenes, and it turns out the method for building the bot&#8217;s vision was checking<a class="more-link" href="/2019/03/17/expanding-our-vision/">Continue reading <span class="screen-reader-text">"Expanding our Vision"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week I wanted to focus on improving the vision for <a href="https://github.com/sc2ad/CelesteBot/tree/qlearning">CelesteBot</a>.</p>



<p>As noted in the last post, 10&#215;10 vision worked fine but anything much bigger tanked the game&#8217;s frame rate. I looked at what the mod was doing behind the scenes, and it turns out the method for building the bot&#8217;s vision was checking for collisions in each tile every frame. Collisions are one of the most expensive calculations in games, so you definitely don&#8217;t want to check for collisions this often. Most game content in Celeste is static, so I decided to try caching this information after collision detection was done. The difference was immediate and significant. Here are the frame rates for the game before and after caching:</p>



<ul><li> Before:<ul><li>10&#215;10: 60 FPS</li><li>12&#215;12: 15 FPS</li><li>15&#215;15: 2 FPS</li><li>20&#215;20: 1 FPS</li><li>30&#215;30: 1 FPS</li></ul></li><li>After:<ul><li>10&#215;10: 60 FPS </li><li>12&#215;12: 60 FPS</li><li>15&#215;15: 60 FPS</li><li>20&#215;20: 60 FPS</li><li>30&#215;30: 60 FPS </li></ul></li></ul>



<p>Undoubtedly there will be some modifications needed in later levels for game entities that move, but this is entirely doable.</p>



<p>I also noticed a bug not previously caught: the bot vision was only detecting generic &#8220;entities&#8221;. It should have been distinguishing wall tiles and spikes as different values within the matrix, but the code wasn&#8217;t able to see SolidTiles or Spikes. I modified the entity fetching code a little to check what kind of entity was being collided with. It checks each entity for collisions, then chooses the colliding entity with highest priority. The priority is currently Entity &lt; Tile &lt; Spike. In addition to this modification, I removed the player from the bot&#8217;s vision. The player is always at the center of vision, so there is no need to render them.</p>



<p>This change revealed another bug: spikes were not being detected at all. The collision detection was being done with a single point at each tile. I decided to try checking collisions for collisions within a square the size of a tile, and suddenly spikes were detectable.</p>



<p>I also made a minor performance improvement. Previously, the bot&#8217;s vision was being rendered by a set of circles. This was inefficient and tanked the frame rate with large vision grids. I changed the circles into small squares, and now the frame rate is a steady 60 even with 30&#215;30 vision.</p>



<p>Finally, I decreased the death timer from 2.5 to 2.2 seconds. This appears to be fast enough that the player can&#8217;t die again before the time has elapsed. Although, it may need to be changed for later levels.</p>



<p>With all these changes in place, I ran NEAT overnight for 200 generations, a process that took about 12 hours. The results were interesting, but mostly unsuccessful. The main problem is that 30&#215;30 = 900, which is a lot of inputs for NEAT to experiment with by iterating through them. It is good for the bot to be able to see this region, but it makes the bot take much longer to learn anything. The other problem was a bug present at 1:49:00. The mod failed to reset the level before running the next organism, resulting in an artificially high fitness for an organism that did not deserve it. NEAT then continued to cling to this type of species for the rest of the simulation, with poor results. I&#8217;m still not sure why this occurred, I tested the death timer duration after this simulation and it reset properly every time. If this occurs again, I&#8217;ll need to do a more thorough investigation.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" class="youtube-player" width="750" height="422" src="https://www.youtube.com/embed/aVTlBXTexzM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>Now that the expanded vision is in place, it&#8217;s time to think about how to get as much training time as possible for the bot. I would like to investigate methods of speeding up Celeste&#8217;s physics. Another useful feature would be the ability to save and load the genome data so that sessions can be carried over between game launches. These will be the main focus of next week&#8217;s work.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">54</post-id>	</item>
		<item>
		<title>HyperLeap to CelesteBot</title>
		<link>/2019/03/02/hyperleap-to-celestebot/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Sat, 02 Mar 2019 22:13:57 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=51</guid>

					<description><![CDATA[I made a massive leap in progress this week due to the magic of social networking. Through connections on the Mt. Celeste Climbing Association Discord, I was referred to sc2ad and his project: CelesteBot. This project has been in progress for months, and much of the work I was trying to accomplish is already done<a class="more-link" href="/2019/03/02/hyperleap-to-celestebot/">Continue reading <span class="screen-reader-text">"HyperLeap to CelesteBot"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I made a massive leap in progress this week due to the magic of social networking. Through connections on the <a href="https://discord.gg/6qjaePQ">Mt. Celeste Climbing Association Discord</a>, I was referred to sc2ad and his project: <a href="https://www.youtube.com/watch?v=mGykjbUxj6I">CelesteBot</a>. This project has been in progress for months, and much of the work I was trying to accomplish is already done and available in the <a href="https://github.com/sc2ad/CelesteBot/tree/qlearning">CelesteBot GitHub repo</a>. There&#8217;s not much in the way of documentation, but by examining the source code and talking to sc2ad, I&#8217;ve been able to start understanding the mod and performing tests with it.</p>



<p>In essence, CelesteBot is an application of NEAT machine learning. It is vision based, it simplifies the region near the player into a grid of colliding tiles and entities. It uses this as input, along with some other parameters like player position, velocity, player stamina, and a Boolean representing whether the player can dash. These inputs are mapped to outputs on the game pad representing in game controls: up, down, left, right, jump, dash, and grab. These controls are then executed in game. This whole process occurs once every frame. The bot&#8217;s effectiveness is determined through a performance metric, it is based on distance toward the next checkpoint. Multiple checkpoints can be tracked sequentially, thus a route through a map can be pre-planned for the bot.</p>



<p>The mod has a lot of user facing settings that can be modified to subtly change the nature of the machine learning algorithm. These include vision size, along with many NEAT specific settings like &#8220;Add Connection Chance&#8221; and &#8220;Add Node Chance&#8221;. The mod also includes several keyboard controls. The most important of these are as follows:</p>



<ul><li>A &#8211; Fitness Append Mode. Allows the user to specify checkpoints for the performance metric.<ul><li>Space &#8211; Append Fitness Marker</li></ul></li><li> &#8211; Begin Learning. Starts the machine learning process.</li><li>, &#8211; Stop Learning. Also resets the player. Species data is still held within memory.</li><li>N &#8211; Hide mod overlay. Allows the game itself to be viewed without the additional clutter. Also improves frame rate, rendering the mod overlay is performance heavy.</li><li>Shift+N &#8211; Show mod overlay. Shows relevant mod information, including a visual representation of the machine&#8217;s brain, the performance metric, and the performance progress over time. The machine&#8217;s brain shows a mapping of the machine&#8217;s &#8220;vision&#8221; to game controls via nodes and connections.</li></ul>



<p>At first, I was interested in seeing whether NEAT would be able to make progress given only one checkpoint placed at the end of the level. This approach would not give a perfect model for each room, but if the bot moved toward it over time, it would end up working. I found that this approach was extremely slow, after 10 generations the bot still had not made significant progress toward exiting the first room.</p>



<p>The second approach I tried was putting a checkpoint at the end of each room. This approach would speed up progress significantly, but would leave less room for interesting decisions from the bot. I also recorded the bot&#8217;s progress from generation 5 through 20. I found that watching the machine&#8217;s brain over time was one of the best ways to gain an intuitive understanding of NEAT. This was significantly faster than the previous approach, but was still quite slow. Due to the nature of NEAT, building models from large input sets takes a long time, as the algorithm typically tries randomly adding one link from one input to one output at a time, and running the simulation. Each simulation takes at least 4 seconds to run, since the mod does not reset the player until no significant progress is made for at least 4 seconds. It doesn&#8217;t sound like a lot, but the time adds up. By generation 20, the bot had only made it to the second room a handful of times. If I could increase the simulation speed of the game, it could be a great help toward training the bot quickly. I believe this is possible, as <a href="https://github.com/ShootMe/CelesteTAS">CelesteTas</a> has a similar feature.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" class="youtube-player" width="750" height="422" src="https://www.youtube.com/embed/xC7iCYS2NAM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>I also noticed the bot couldn&#8217;t &#8220;see&#8221; the next platform occasionally, as it was outside its limited vision. By default, the bot can only see a 10 by 10 grid of tiles around itself. Celeste&#8217;s dash mechanic, however, can traverse this distance almost instantaneously. For the bot to know it needs to dash, it needs to be able to see what is should dash to. To remedy this, I tried running NEAT with a 30 by 30 grid. Unfortunately, this proved to be more than my computer could handle, frame rates were in the single digits. I looked at the source code for building the bot&#8217;s vision and I believe I can make it more efficient. Being able to run NEAT with more vision could be critical to significant bot improvements.</p>



<p>I also discovered a couple bugs and some needed improvements in the fundamental processes of the mod. When the player dies, the mod is supposed to wait until the death animation is complete and then reset the player to the beginning of the map. However, if the player dies again before the reset is triggered, the reset is unable to trigger as the death animation takes priority. I examined the code in question, the death animation wait is a simple stopwatch set to 2.5 seconds. I think this timing is just a tad too generous, I will need to experiment with smaller timings later to try to fix this. It isn&#8217;t a huge bug, but it occasionally ruins a simulation for a particular organism.</p>



<p>The other bug relates directly to the vision of the bot. The bot vision appears inconsistent from the hit boxes surrounding it. This ends up being critical at the end of the first room, where there is a single block that the bot can&#8217;t see sticking out of a wall. The bot ends up walking to the wall and getting stuck under the block, followed by a reset. For the bot to be able to account for the block, it needs to be able to see it.</p>



<p>The mod creator, sc2ad, was also working on support for another form of machine learning: Q Learning. Q Learning is fundamentally different from NEAT, it is a form of reinforcement learning. It essentially takes in all the same input as NEAT, but then chooses an output state based on what it has seen before or random chance. There is a possible output state for every legal combination of game pad button presses. The algorithm is then rewarded based on it&#8217;s progress toward a checkpoint. The learning process appears much more chaotic than NEAT, it is somewhat similar to a human randomly mashing buttons at first. After a while it tends to move toward it&#8217;s goal more, but it randomly backtracks a lot when it shouldn&#8217;t. It tends to move much faster than NEAT, though, favoring the dash much more than NEAT ever did. I recorded 500 iterations to get an idea of how it compared to NEAT.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" class="youtube-player" width="750" height="422" src="https://www.youtube.com/embed/4cnLSv7YKAQ?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent" allowfullscreen="true" style="border:0;" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe>
</div></figure>



<p>As an unrelated aside, I submitted a <a href="https://github.com/EverestAPI/EverestAPI.github.io/pull/5">pull request</a> to add some method hooking basic information to the <a href="https://everestapi.github.io/">Everest wiki</a>. Hopefully those will get accepted, and will be of some help to future modders.</p>



<p>Next week&#8217;s goals include: fixing CelesteBot&#8217;s vision inconsistencies, fixing CelesteBot&#8217;s death timer, and improving CelesteBot&#8217;s vision generation performance. I may also look into increasing Celeste&#8217;s simulation speed and investigate other machine learning methods.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">51</post-id>	</item>
		<item>
		<title>Game Pads and Entities</title>
		<link>/2019/02/24/game-pads-and-entities/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Mon, 25 Feb 2019 01:49:45 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=32</guid>

					<description><![CDATA[This week was for the technical fundamentals of MadelineAI. My objectives were to develop a way for my mod to simulate game pad inputs, obtain the location of the player, and obtain level tile data. Celeste runs on the Monocle engine, a proprietary engine developed by Matt Thorson. Monocle checks the game pad state every<a class="more-link" href="/2019/02/24/game-pads-and-entities/">Continue reading <span class="screen-reader-text">"Game Pads and Entities"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>This week was for the technical fundamentals of MadelineAI. My objectives were to develop a way for my mod to simulate game pad inputs, obtain the location of the player, and obtain level tile data.</p>



<p>Celeste runs on the Monocle engine, a proprietary engine developed by Matt Thorson. Monocle checks the game pad state every frame and feeds that information to the game. The game then proceeds with these inputs. I was able to hook into the Monocle.MInput.Update function to insert my own code during runtime. The function essentially creates a virtual game pad using the Microsoft XNA framework, with the desired inputs pressed or released. It then sets the game pad variable held by MInput to this new game pad. These steps are sufficient to simulate button presses, but they are not sufficient for directional input. MInput has a private function UpdateVirtualInputs which is called after the original Update function. This function is required to get directional input to work. Unfortunately, it is private, and therefore inaccessible to my mod. To circumvent this, I used a program called <a href="https://github.com/0xd4d/dnSpy">dnSpy</a>. It allows a user to load an executable&#8217;s source code, modify components, and then recompile the executable. I changed the UpdateVirtualInputs function from private to public, added the function call to the end of MAI, and now MAI supports full simulated game pad input. My solution was heavily based on <a href="https://github.com/ShootMe/CelesteTAS">CelesteTAS</a> and <a href="https://github.com/EverestAPI/CelesteTAS-EverestInterop">CelesteTAS-EverestInterop</a>. To test my simulated game pad functionality, I wrote a couple quick scripts making use of the jump and dash mechanics.</p>



<ul data-carousel-extra='{"blog_id":1,"permalink":"https:\/\/bercribehome.wpcomstaging.com\/2019\/02\/24\/game-pads-and-entities\/"}' class="wp-block-gallery columns-2 is-cropped"><li class="blocks-gallery-item"><figure><img data-attachment-id="47" data-permalink="/2019/02/24/game-pads-and-entities/ezgif-2-4d86f222f34e-2/" data-orig-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/56f7b-ezgif-2-4d86f222f34e-1.gif?fit=600%2C338&amp;ssl=1" data-orig-size="600,338" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ezgif-2-4d86f222f34e" data-image-description="" data-image-caption="" data-medium-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/56f7b-ezgif-2-4d86f222f34e-1.gif?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/56f7b-ezgif-2-4d86f222f34e-1.gif?fit=600%2C338&amp;ssl=1" loading="lazy" width="600" height="338" src="https://i2.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/56f7b-ezgif-2-4d86f222f34e-1.gif?resize=600%2C338&#038;ssl=1" alt="" data-id="47" data-link="https://www.projectzoran.com/index.php/2019/02/24/game-pads-and-entities/ezgif-2-4d86f222f34e-2/" class="wp-image-47" data-recalc-dims="1" /></figure></li><li class="blocks-gallery-item"><figure><img data-attachment-id="48" data-permalink="/2019/02/24/game-pads-and-entities/ezgif-2-d7bfced88bde/" data-orig-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/38fdb-ezgif-2-d7bfced88bde.gif?fit=600%2C338&amp;ssl=1" data-orig-size="600,338" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ezgif-2-d7bfced88bde" data-image-description="" data-image-caption="" data-medium-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/38fdb-ezgif-2-d7bfced88bde.gif?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/38fdb-ezgif-2-d7bfced88bde.gif?fit=600%2C338&amp;ssl=1" loading="lazy" width="600" height="338" src="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/38fdb-ezgif-2-d7bfced88bde.gif?resize=600%2C338&#038;ssl=1" alt="" data-id="48" data-link="https://www.projectzoran.com/index.php/2019/02/24/game-pads-and-entities/ezgif-2-d7bfced88bde/" class="wp-image-48" data-recalc-dims="1" /></figure></li></ul>



<p>The second part was to get information about the game state. After a lot of experimentation, I have landed on a method I believe to be as clean and efficient as possible. MAI hooks into the Monocle.EntityList.Add_Entity function. When this is called, MAI grabs a reference to the Celeste Scene. The scene contains a list of Entities, which is essentially everything on screen that we care about. From these entities, we can determine whether we are dealing with a Player, Spikes, Spring, SolidTiles, or something else. Each Entity also has a lot of information about itself, including its position and Collider. This is all that is required for a machine to understand the level.</p>



<p>I have been considering how best to translate this information to the machine. <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O</a> heavily simplifies the information provided to the machine, using a small grid with each square marked as a tile, enemy, or Mario. This works due to the forgiving nature of Mario&#8217;s platforming, but Celeste is a much more precise game. I think a better approach for Celeste would use a much larger grid to represent information, with each square representing a pixel. Every frame, the grid would be populated with information to represent the player, tiles, spikes, springs, and any other entities the machine needs to know about. The only real way to know is to try it, and that&#8217;s what I intend to do.</p>



<p>That&#8217;s about it for this week, there&#8217;s less interesting abstract stuff to talk about since time was spent developing technical solutions. Next week&#8217;s objectives will be building the grid from the Entity data, developing a performance metric, and beginning construction of the NEAT algorithm.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">32</post-id>	</item>
		<item>
		<title>MadelineAI 100</title>
		<link>/2019/02/18/madelineai-100/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Tue, 19 Feb 2019 01:40:00 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=29</guid>

					<description><![CDATA[Progress has been slow this week, it feels like learning new technologies takes longer than developing them sometimes. My goals for the week have been to find Celeste mirrors to the elements present in MarI/O, and begin developing a technical prototype. These elements included save states and a fitness metric. I wanted some kind of<a class="more-link" href="/2019/02/18/madelineai-100/">Continue reading <span class="screen-reader-text">"MadelineAI 100"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>Progress has been slow this week, it feels like learning new technologies takes longer than developing them sometimes. My goals for the week have been to find Celeste mirrors to the elements present in <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O</a>, and begin developing a technical prototype. These elements included save states and a fitness metric.</p>



<p>I wanted some kind of save state like functionality for my Celeste TASBot. I decided to investigate some existing tassing solutions to see how save states were handled. <a href="http://tasvideos.org/EmulatorResources/LibTAS.html">LibTAS</a> actually does support save states for some modern titles including Celeste. However, it only runs on Linux and the save states can take several seconds to load, which is not ideal when hundreds of thousands of runs are required for machine learning training. <a href="https://github.com/ShootMe/CelesteTAS">CelesteTAS</a> decided not to use save states at all when helping tassers develop their speed runs. Instead, it just plays the inputs back from the beginning of the level every time, relying on the fact that the game runs quickly and the levels are relatively short. In the end I decided I&#8217;ll either have to abandon save state functionality in favor of resetting the bot at the start of each level, or implement it in a way similar to CelesteTAS.</p>



<p>In Mario, the goal is very simple &#8211; move right. It is easy to formulate this goal to a machine in terms of a performance metric. In Celeste, the goal is not quite as simple. One approach is to track the maximum distance the bot has traveled toward the end of the level . Level 1-A is fairly linear, so this approach might be sufficient. Level 2-A, however, has 2 different cut scene triggers in different parts of the level. This requires backtracking, for which a simple performance metric would be inefficient, if not impossible. Another approach is to predetermine the bot&#8217;s route from room to room, and leave the mechanics to the machine learning. However, this approach would miss out on any interesting discoveries the bot could make by travelling a different route. After discussing with a Celeste tasser and modder, I decided the metric should be based upon the maximum distance traveled to the next checkpoint in the level. In level 1-A, there is 1 checkpoint &#8211; the end of the level. In level 2-A there are 3 checkpoints &#8211; the cut scene triggers and the end of the level. I believe this approach will help define the bot&#8217;s goals better without doing too much hard coding. This metric would of course factor in speed, favoring faster times to the same location.</p>



<p>With these elements defined in abstract terms, it was time to begin developing MadelineAI (MAI). This would be a mod written in C# using <a href="https://everestapi.github.io/">Everest</a>. Having no prior experience with mod development, I naively assumed writing mods was like writing games or other applications: it would have some main function that executed everything else. Everest mods are actually C# libraries, though, they are loaded when the application starts and function by hooking into existing game methods. Typical Everest mods need a Module and a ModuleSettings. The Module loads and unloads the methods used in the mod, and the ModuleSettings contains user facing options for the mod accessible in the main menu of Celeste. I was able to compile a mod and have it loaded by Everest, although it doesn&#8217;t do much besides look good so far.</p>



<figure class="wp-block-image"><img data-attachment-id="30" data-permalink="/2019/02/18/madelineai-100/20190218201428_1/" data-orig-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/8c924-20190218201428_1.jpg?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20190218201428_1" data-image-description="" data-image-caption="" data-medium-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/8c924-20190218201428_1.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/8c924-20190218201428_1.jpg?fit=750%2C422&amp;ssl=1" loading="lazy" width="750" height="422" src="https://i1.wp.com/bercribehome.wpcomstaging.com/wp-content/uploads/2019/12/8c924-20190218201428_1.jpg?resize=750%2C422&#038;ssl=1" alt="" class="wp-image-30" data-recalc-dims="1" /></figure>



<p>The rest of my time was mostly spent examining the source code for CelesteTAS in an attempt to gleam some understanding of the Everest framework. My goals for for the coming week is to be able to supply input to the game and to fetch character and terrain information from the game via MAI. Follow up goals include building the NEAT infrastructure within MAI, or accessing the MarI/O LUA code from MAI.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">29</post-id>	</item>
		<item>
		<title>Neural networks playing platformers</title>
		<link>/2019/02/10/neural-networks-playing-platformers/</link>
		
		<dc:creator><![CDATA[mawz]]></dc:creator>
		<pubDate>Mon, 11 Feb 2019 00:48:27 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.projectzoran.com/?p=24</guid>

					<description><![CDATA[I decided a good place to start would be the MarI/O source code. MarI/O is designed to work with the BizHawk emulator. This emulator is designed with TASBots in mind, it allows the saving and loading of save states and execution of LUA scripts. MarI/O is essentially a huge LUA script. It works on the<a class="more-link" href="/2019/02/10/neural-networks-playing-platformers/">Continue reading <span class="screen-reader-text">"Neural networks playing platformers"</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I decided a good place to start would be the <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O</a> source code. MarI/O is designed to work with the <a href="http://tasvideos.org/BizHawk.html">BizHawk emulator</a>. This emulator is designed with TASBots in mind, it allows the saving and loading of save states and execution of LUA scripts. MarI/O is essentially a huge LUA script. It works on the assumption that it is always beneficial for Mario to move towards the right side of the screen, and uses a Fitness metric calculated with this assumption in mind. It uses this metric to judge the success of neural networks generated via the <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">NEAT</a> method. The system iteratively tests these networks by having them play Mario. It then combines successful networks and eliminates unsuccessful ones. This is a gross oversimplification of the process, the system requires hundreds, if not thousands of repetitions to yield much success.</p>



<p>To test my understanding of the system, I attempted a modification of MarI/O that would allow it to play Castlevania instead. MarI/O fetches Mario&#8217;s location, tile information, and enemy information by reading the RAM of the executing ROM. I had to modify this to fetch Simon&#8217;s location and the location of enemies. I was unable to make a direct translation from Mario&#8217;s tile reading method to Castlevania&#8217;s, so I left this element out of the equation. I then allowed the system to run over and over again. By generation 8, the bot was able to make it to the second room sometimes. At this point, I realized that the Fitness metric used by Mario was too simple for Castlevania since the rightmost side of the screen is not the end of the second room, the player must instead descend the stairs into the basement. I also discovered that Simon&#8217;s position wasn&#8217;t being tracked globally, it was only being tracked per room. Thus, the Fitness metric stopped counting after the first room. If repeated with these fixes, this experiment could probably get better results. The earliest effective strategy for the bot was a stutter step, involving using the whip every second or so and walking to the right. The bot made it to the end of the first room before being reset. In later generations, the most effective strategy was to jump over ghosts and damage boost past them. More detailed data about the Castlevania training can be found <a href="https://pastebin.com/16pqaUMK">here</a>.</p>



<p>I also began preparing to apply the NEAT system to a more recent game &#8211; <a href="http://www.celestegame.com/">Celeste</a>. Celeste has a large speed running and modding scene, it also features complex mechanics and entirely deterministic gameplay. These features make it an excellent candidate for NEAT. I installed <a href="https://everestapi.github.io/">Everest</a>, a Celeste mod loader and modding API. By opening the game and enabling debug mode, I discovered that the necessary components for NEAT were made readily available by Everest: the player&#8217;s position, the level tiles, and special entities like spikes and springs. The stages were even labeled in numerically increasing order from the start to the end of the level. This should make it possible to either develop a mod that performs NEAT in a self contained format, or develop a mod that supplies entity information for use in a 3rd party program running NEAT. I&#8217;ll have to experiment a lot with Fitness metrics. One option is to track the distance the player is from the end of the level at any given time. Another possibility involves tracking the distance the player is from the next stage toward the end of the level. This would require more work initially, but might yield faster results. I&#8217;m excited to start applying NEAT to Celeste in the near future.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">27</post-id>	</item>
	</channel>
</rss>
