<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Background Academic Research | Your awesome title</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Background Academic Research" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In order to stand on the shoulders of giants in academia, we must know who has come before us. To accomplish this, I first compiled a list of academic research papers that seemed like they might be relevant to my research interests: The 2010 Mario AI Championship: Level Generation TrackOn Game Art, Circuit Bending and Speedrunning as Counter-Practice: &#39;Hard&#39; and &#39;Soft&#39; Nonexistence From NES-4021 to moSMB3.wmv: Speedrunning the Serial Interface A Practiced Practice: Speedrunning Through Space With de Certeau and Virilio Some Studies in Machine Learning Using the Game of Checkers Constraint-based generalization: learning game-playing plans from single examples The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces Learning To Play the Game of Chess Temporal difference learning applied to a high-performance game-playing program An Empirical Study of Machine Learning Algorithms Applied to Modeling Player Behavior in a &quot;First Person Shooter&quot; Video Game Real-time neuroevolution in the NERO video game Machine learning in digital games: a survey Action-Conditional Video Prediction using Deep Networks in Atari Games DeepMind Lab The 2009 Mario AI Competition The Mario AI Benchmark and Competitions The 2010 Mario AI Championship: Level Generation Track Evolving Neural Networks through Augmenting Topologies StarCraft II: A New Challenge for Reinforcement Learning TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game The Current State of StarCraft AI Competitions and Bots On Reinforcement Learning for Full-length Game of StarCraft Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology General Video Game AI: Competition, Challenges and Opportunities Rapid and Reliable Adaptation of Video Game AI Monte-Carlo Tree Search: A New Framework for Game AI Pogamut 3 Can Assist Developers in Building AI (Not Only) for Their Videogame Agents Game AI revisited Mind games [computer game AI] Rapid adaptation of video game AI I then narrowed this list down to the 5 most relevant documents. DeepMind Lab documents the DeepMind team&#39;s development of a platform for testing AI in perceptually and physically rich environments. They posit that an agent can be sufficiently trained given only RGB data and reward. Velocity information can be useful. The agent can interact with its environment by moving in 6 axes and rotating its point of view. This is encouraging for my research, as I might be able to directly interpret monitor output for my game without doing anything special. Evolving Neural Networks through Augmenting Topologies provides a comprehensive description and analysis of NeuroEvolution of Augmented Topologies (NEAT), a refined method for generating neural networks. It shows that by using historical markings, protecting innovation through speciation, and incrimentally growing from minimal structures instead of random initial structure is much more efficient than previous alternatives. While this paper does not specifically relate to video games, it was the foundation of SethBling&#39;s AI project, MarI/O, so I thought it was worth reading. General Video Game AI: Competition, Challenges, and Opportunities gives an account of the General Video Game AI (GVGAI) Competition. This competition has contestants develop AI with the intention of successfully playing a wide variety of 2D video games without being provided a rule set. Results were inconclusive, with winning bots using a variety of techniques such as evolutionary algorithms, random walks, A*, and others. Clearly there is a lot of work to be done in this field. The Mario AI Benchmark and Competitions shows the synopsis of a competition for AI developers to create an agent that can play Super Mario Bros the best. The results showed that the A* based agents performed the best, outclassing machine learning agents. However, this proved to not be the case for the competition the next year that included more complex mechanics. A* techniques could be worth exploring for my TASBot generator, but machine learning is likely going to be more effective for high complexity games. Real-time neuroevolution in the NERO video game demonstrates how NEAT can be used in real time (rtNEAT) and applied to video game AIs. This article was interesting because it directly tied NEAT to video games, but it might not be very relevant to my interests. TASBot generation does not need to run in real time, it has plenty of time to run the full NEAT algorithm before finalizing the route." />
<meta property="og:description" content="In order to stand on the shoulders of giants in academia, we must know who has come before us. To accomplish this, I first compiled a list of academic research papers that seemed like they might be relevant to my research interests: The 2010 Mario AI Championship: Level Generation TrackOn Game Art, Circuit Bending and Speedrunning as Counter-Practice: &#39;Hard&#39; and &#39;Soft&#39; Nonexistence From NES-4021 to moSMB3.wmv: Speedrunning the Serial Interface A Practiced Practice: Speedrunning Through Space With de Certeau and Virilio Some Studies in Machine Learning Using the Game of Checkers Constraint-based generalization: learning game-playing plans from single examples The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces Learning To Play the Game of Chess Temporal difference learning applied to a high-performance game-playing program An Empirical Study of Machine Learning Algorithms Applied to Modeling Player Behavior in a &quot;First Person Shooter&quot; Video Game Real-time neuroevolution in the NERO video game Machine learning in digital games: a survey Action-Conditional Video Prediction using Deep Networks in Atari Games DeepMind Lab The 2009 Mario AI Competition The Mario AI Benchmark and Competitions The 2010 Mario AI Championship: Level Generation Track Evolving Neural Networks through Augmenting Topologies StarCraft II: A New Challenge for Reinforcement Learning TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game The Current State of StarCraft AI Competitions and Bots On Reinforcement Learning for Full-length Game of StarCraft Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology General Video Game AI: Competition, Challenges and Opportunities Rapid and Reliable Adaptation of Video Game AI Monte-Carlo Tree Search: A New Framework for Game AI Pogamut 3 Can Assist Developers in Building AI (Not Only) for Their Videogame Agents Game AI revisited Mind games [computer game AI] Rapid adaptation of video game AI I then narrowed this list down to the 5 most relevant documents. DeepMind Lab documents the DeepMind team&#39;s development of a platform for testing AI in perceptually and physically rich environments. They posit that an agent can be sufficiently trained given only RGB data and reward. Velocity information can be useful. The agent can interact with its environment by moving in 6 axes and rotating its point of view. This is encouraging for my research, as I might be able to directly interpret monitor output for my game without doing anything special. Evolving Neural Networks through Augmenting Topologies provides a comprehensive description and analysis of NeuroEvolution of Augmented Topologies (NEAT), a refined method for generating neural networks. It shows that by using historical markings, protecting innovation through speciation, and incrimentally growing from minimal structures instead of random initial structure is much more efficient than previous alternatives. While this paper does not specifically relate to video games, it was the foundation of SethBling&#39;s AI project, MarI/O, so I thought it was worth reading. General Video Game AI: Competition, Challenges, and Opportunities gives an account of the General Video Game AI (GVGAI) Competition. This competition has contestants develop AI with the intention of successfully playing a wide variety of 2D video games without being provided a rule set. Results were inconclusive, with winning bots using a variety of techniques such as evolutionary algorithms, random walks, A*, and others. Clearly there is a lot of work to be done in this field. The Mario AI Benchmark and Competitions shows the synopsis of a competition for AI developers to create an agent that can play Super Mario Bros the best. The results showed that the A* based agents performed the best, outclassing machine learning agents. However, this proved to not be the case for the competition the next year that included more complex mechanics. A* techniques could be worth exploring for my TASBot generator, but machine learning is likely going to be more effective for high complexity games. Real-time neuroevolution in the NERO video game demonstrates how NEAT can be used in real time (rtNEAT) and applied to video game AIs. This article was interesting because it directly tied NEAT to video games, but it might not be very relevant to my interests. TASBot generation does not need to run in real time, it has plenty of time to run the full NEAT algorithm before finalizing the route." />
<link rel="canonical" href="/2019/02/03/background-academic-research/" />
<meta property="og:url" content="/2019/02/03/background-academic-research/" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-03T21:33:56-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Background Academic Research" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"/2019/02/03/background-academic-research/","dateModified":"2019-02-03T21:33:56-08:00","datePublished":"2019-02-03T21:33:56-08:00","headline":"Background Academic Research","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/03/background-academic-research/"},"description":"In order to stand on the shoulders of giants in academia, we must know who has come before us. To accomplish this, I first compiled a list of academic research papers that seemed like they might be relevant to my research interests: The 2010 Mario AI Championship: Level Generation TrackOn Game Art, Circuit Bending and Speedrunning as Counter-Practice: &#39;Hard&#39; and &#39;Soft&#39; Nonexistence From NES-4021 to moSMB3.wmv: Speedrunning the Serial Interface A Practiced Practice: Speedrunning Through Space With de Certeau and Virilio Some Studies in Machine Learning Using the Game of Checkers Constraint-based generalization: learning game-playing plans from single examples The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces Learning To Play the Game of Chess Temporal difference learning applied to a high-performance game-playing program An Empirical Study of Machine Learning Algorithms Applied to Modeling Player Behavior in a &quot;First Person Shooter&quot; Video Game Real-time neuroevolution in the NERO video game Machine learning in digital games: a survey Action-Conditional Video Prediction using Deep Networks in Atari Games DeepMind Lab The 2009 Mario AI Competition The Mario AI Benchmark and Competitions The 2010 Mario AI Championship: Level Generation Track Evolving Neural Networks through Augmenting Topologies StarCraft II: A New Challenge for Reinforcement Learning TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game The Current State of StarCraft AI Competitions and Bots On Reinforcement Learning for Full-length Game of StarCraft Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology General Video Game AI: Competition, Challenges and Opportunities Rapid and Reliable Adaptation of Video Game AI Monte-Carlo Tree Search: A New Framework for Game AI Pogamut 3 Can Assist Developers in Building AI (Not Only) for Their Videogame Agents Game AI revisited Mind games [computer game AI] Rapid adaptation of video game AI I then narrowed this list down to the 5 most relevant documents. DeepMind Lab documents the DeepMind team&#39;s development of a platform for testing AI in perceptually and physically rich environments. They posit that an agent can be sufficiently trained given only RGB data and reward. Velocity information can be useful. The agent can interact with its environment by moving in 6 axes and rotating its point of view. This is encouraging for my research, as I might be able to directly interpret monitor output for my game without doing anything special. Evolving Neural Networks through Augmenting Topologies provides a comprehensive description and analysis of NeuroEvolution of Augmented Topologies (NEAT), a refined method for generating neural networks. It shows that by using historical markings, protecting innovation through speciation, and incrimentally growing from minimal structures instead of random initial structure is much more efficient than previous alternatives. While this paper does not specifically relate to video games, it was the foundation of SethBling&#39;s AI project, MarI/O, so I thought it was worth reading. General Video Game AI: Competition, Challenges, and Opportunities gives an account of the General Video Game AI (GVGAI) Competition. This competition has contestants develop AI with the intention of successfully playing a wide variety of 2D video games without being provided a rule set. Results were inconclusive, with winning bots using a variety of techniques such as evolutionary algorithms, random walks, A*, and others. Clearly there is a lot of work to be done in this field. The Mario AI Benchmark and Competitions shows the synopsis of a competition for AI developers to create an agent that can play Super Mario Bros the best. The results showed that the A* based agents performed the best, outclassing machine learning agents. However, this proved to not be the case for the competition the next year that included more complex mechanics. A* techniques could be worth exploring for my TASBot generator, but machine learning is likely going to be more effective for high complexity games. Real-time neuroevolution in the NERO video game demonstrates how NEAT can be used in real time (rtNEAT) and applied to video game AIs. This article was interesting because it directly tied NEAT to video games, but it might not be very relevant to my interests. TASBot generation does not need to run in real time, it has plenty of time to run the full NEAT algorithm before finalizing the route.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Your awesome title" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Your awesome title</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Background Academic Research</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-02-03T21:33:56-08:00" itemprop="datePublished">Feb 3, 2019
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">{"login"=>"bercribe", "email"=>"matoska.polar.waltz@gmail.com", "display_name"=>"mawz", "first_name"=>"", "last_name"=>""}</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><!-- wp:paragraph --></p>
<p>In order to stand on the shoulders of giants in academia, we must know who has come before us. To accomplish this, I first compiled a list of academic research papers that seemed like they might be relevant to my research interests:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul>
<li>The 2010 Mario AI Championship: Level Generation TrackOn Game Art, Circuit Bending and Speedrunning as Counter-Practice: 'Hard' and 'Soft' Nonexistence</li>
<li>From NES-4021 to moSMB3.wmv: Speedrunning the Serial Interface</li>
<li>A Practiced Practice: Speedrunning Through Space With de Certeau and Virilio</li>
<li>Some Studies in Machine Learning Using the Game of Checkers</li>
<li>Constraint-based generalization: learning game-playing plans from single examples</li>
<li> The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces</li>
<li> Learning To Play the Game of Chess</li>
<li>Temporal difference learning applied to a high-performance game-playing program</li>
<li>An Empirical Study of Machine Learning Algorithms Applied to Modeling Player Behavior in a "First Person Shooter" Video Game</li>
<li>Real-time neuroevolution in the NERO video game</li>
<li>Machine learning in digital games: a survey</li>
<li>Action-Conditional Video Prediction using Deep Networks in Atari Games</li>
<li> DeepMind Lab</li>
<li>The 2009 Mario AI Competition</li>
<li>The Mario AI Benchmark and Competitions</li>
<li>The 2010 Mario AI Championship: Level Generation Track</li>
<li> Evolving Neural Networks through Augmenting Topologies</li>
<li>StarCraft II: A New Challenge for Reinforcement Learning</li>
<li>TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game</li>
<li>The Current State of StarCraft AI Competitions and Bots</li>
<li>On Reinforcement Learning for Full-length Game of StarCraft</li>
<li>Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games</li>
<li>StarCraft as a Testbed for Engineering Complex Distributed Systems Using Cognitive Agent Technology</li>
<li>General Video Game AI: Competition, Challenges and Opportunities </li>
<li>Rapid and Reliable Adaptation of Video Game AI</li>
<li>Monte-Carlo Tree Search: A New Framework for Game AI </li>
<li>Pogamut 3 Can Assist Developers in Building AI (Not Only) for Their Videogame Agents</li>
<li>Game AI revisited</li>
<li>Mind games [computer game AI]</li>
<li>Rapid adaptation of video game AI</li>
</ul>
<p><!-- /wp:list --></p>
<p><!-- wp:paragraph --></p>
<p>I then narrowed this list down to the 5 most relevant documents.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><a href="https://arxiv.org/pdf/1612.03801.pdf">DeepMind Lab</a> documents the DeepMind team's development of a platform for testing AI in perceptually and physically rich environments. They posit that an agent can be sufficiently trained given only RGB data and reward. Velocity information can be useful. The agent can interact with its environment by moving in 6 axes and rotating its point of view. This is encouraging for my research, as I might be able to directly interpret monitor output for my game without doing anything special.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">Evolving Neural Networks through Augmenting Topologies</a> provides a comprehensive description and analysis of NeuroEvolution of Augmented Topologies (NEAT), a refined method for generating neural networks. It shows that by using historical markings, protecting innovation through speciation, and incrimentally growing from minimal structures instead of random initial structure is much more efficient than previous alternatives. While this paper does not specifically relate to video games, it was the foundation of <a href="https://www.youtube.com/channel/UC8aG3LDTDwNR1UQhSn9uVrw">SethBling</a>'s AI project, <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O</a>, so I thought it was worth reading.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11853/12281">General Video Game AI: Competition, Challenges, and Opportunities</a> gives an account of the General Video Game AI (GVGAI) Competition. This competition has contestants develop AI with the intention of successfully playing a wide variety of 2D video games without being provided a rule set. Results were inconclusive, with winning bots using a variety of techniques such as evolutionary algorithms, random walks, A*, and others. Clearly there is a lot of work to be done in this field.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><a href="https://ieeexplore-ieee-org.proxy.lib.umich.edu/document/6156425">The Mario AI Benchmark and Competitions</a> shows the synopsis of a competition for AI developers to create an agent that can play Super Mario Bros the best. The results showed that the A* based agents performed the best, outclassing machine learning agents. However, this proved to not be the case for the competition the next year that included more complex mechanics. A* techniques could be worth exploring for my TASBot generator, but machine learning is likely going to be more effective for high complexity games.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p><a href="https://ieeexplore-ieee-org.proxy.lib.umich.edu/document/1545941">Real-time neuroevolution in the NERO video game</a> demonstrates how NEAT can be used in real time (rtNEAT) and applied to video game AIs. This article was interesting because it directly tied NEAT to video games, but it might not be very relevant to my interests. TASBot generation does not need to run in real time, it has plenty of time to run the full NEAT algorithm before finalizing the route.</p>
<p><!-- /wp:paragraph --></p>

  </div><a class="u-url" href="/2019/02/03/background-academic-research/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Your awesome title</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Your awesome title</li><li><a class="u-email" href="mailto:your-email@example.com">your-email@example.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
